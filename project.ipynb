{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Intro to Hardware Security and Trust Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.cluster import KMeans,DBSCAN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "import os\n",
    "from statistics import mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Splitting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_path = 'C:\\\\Users\\patri\\\\git\\\\HSTFinalProject\\\\Classifier-for-Hardware-Trojan-Detection\\\\ROFreq\\\\ROFreq\\\\Chip'\n",
    "csv_path ='C:\\\\Users\\patri\\\\git\\HSTFinalProject\\Classifier-for-Hardware-Trojan-Detection\\ROFreq_C\\Chip'\n",
    "\n",
    "for i in np.arange(1,34):\n",
    "    data_xls = pd.read_excel('{}{}.xlsx'.format(xlsx_path,i), dtype=str, index_col=None)\n",
    "    data_xls.to_csv('{}{}.csv'.format(csv_path,i), encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_read(chip_num,type,csv_path):\n",
    "    data= []\n",
    "    data_list= []\n",
    "    label_list = np.zeros(25)\n",
    "    label_list[0] = 1\n",
    "    label_list[-1] = 1\n",
    "    with open('{}{}.csv'.format(csv_path,chip_num)) as csvfile:\n",
    "        csv_reader = csv.reader(csvfile)\n",
    "   \n",
    "        for row in csv_reader:\n",
    "            # rounding\n",
    "            row = [round(float(num[0:12]),3) for num in row]     \n",
    "            data_list.append(row)   \n",
    "\n",
    "        if type == 'TI':\n",
    "            data.append(data_list[0])\n",
    "            data.append(data_list[-1])\n",
    "            label = [1,1]\n",
    "        elif type == 'TF':\n",
    "            data = data_list[1:-1]\n",
    "            label = label_list[1:-1]\n",
    "        else:\n",
    "            data = data_list\n",
    "            label = label_list \n",
    "                  \n",
    "        \n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(num_sel,case_sel,csv_path):\n",
    "    chips_num = np.arange(1,34)\n",
    "    indices = range(33)\n",
    "    # randomly select #num chips\n",
    "    sel = random.sample(indices,num_sel)\n",
    "    # split tain and test data\n",
    "    train_chips = chips_num[sel]\n",
    "    test_chips = np.delete(chips_num,sel)\n",
    "    print('Training chips num: ',train_chips)\n",
    "    temp = []\n",
    "\n",
    "    for i in range(int(num_sel/2)):\n",
    "        temp.extend(['TF','TI'])\n",
    " \n",
    "    type_sel_1 = random.sample(temp,num_sel)\n",
    "    type_sel_3 = random.choices(['TI','TF'],k=num_sel)\n",
    "    \n",
    "    if case_sel == 1:\n",
    "        print('Type selection:', type_sel_1)\n",
    "        print('TI:',type_sel_1.count('TI'))\n",
    "        print('TF:',type_sel_1.count('TF'))\n",
    "\n",
    "    else:\n",
    "        print('Type selection:', type_sel_3)\n",
    "        print('TI:',type_sel_3.count('TI'))\n",
    "        print('TF:',type_sel_3.count('TF'))\n",
    "\n",
    "    cnt = 0\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "\n",
    "    for chip_num in train_chips:\n",
    "        if case_sel == 1:\n",
    "            data,label = csv_read(chip_num,type_sel_1[cnt],csv_path)\n",
    "        elif case_sel ==3:\n",
    "            data,label = csv_read(chip_num,type_sel_3[cnt],csv_path)\n",
    "        train_data.extend(data)\n",
    "        train_label.extend(label)\n",
    "        cnt += 1\n",
    "\n",
    "    test_data = []\n",
    "    test_label = []\n",
    "    for chip_num in test_chips:\n",
    "        data,label = csv_read(chip_num,'ALL',csv_path)\n",
    "        test_data.extend(data)\n",
    "        test_label.extend(label)\n",
    "    \n",
    "    return train_data, train_label, test_data, test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  CASE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training chips num:  [12 20  2  7 31 26 18  5 19 11 30 24 16 17  4 33  8 21 29 23 27 28  9 10]\n",
      "Type selection: ['TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TF', 'TI', 'TF', 'TF', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [11 10 32  2 30 33 28 21  8  1  4 27]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI', 'TF', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [15 21  1 14  7 28]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TF', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n"
     ]
    }
   ],
   "source": [
    "# arg1 => number of training samples\n",
    "# arg2 => number of case (enter 1 or 3 only)\n",
    "train24_data, train24_label, test24_data, test24_label = train_test_split(24,1,csv_path)\n",
    "train12_data, train12_label, test12_data, test12_label = train_test_split(12,1,csv_path)\n",
    "train6_data, train6_label, test6_data, test6_label = train_test_split(6,1,csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>184.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>217.2</td>\n",
       "      <td>227.6</td>\n",
       "      <td>217.2</td>\n",
       "      <td>224.8</td>\n",
       "      <td>215.2</td>\n",
       "      <td>246.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>217.2</td>\n",
       "      <td>227.6</td>\n",
       "      <td>217.2</td>\n",
       "      <td>224.8</td>\n",
       "      <td>215.2</td>\n",
       "      <td>246.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184.8</td>\n",
       "      <td>198.0</td>\n",
       "      <td>216.4</td>\n",
       "      <td>228.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>214.4</td>\n",
       "      <td>244.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185.2</td>\n",
       "      <td>198.0</td>\n",
       "      <td>216.4</td>\n",
       "      <td>228.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>214.4</td>\n",
       "      <td>244.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>184.8</td>\n",
       "      <td>198.0</td>\n",
       "      <td>216.4</td>\n",
       "      <td>228.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>214.4</td>\n",
       "      <td>244.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>148.4</td>\n",
       "      <td>157.6</td>\n",
       "      <td>174.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>174.8</td>\n",
       "      <td>177.6</td>\n",
       "      <td>170.8</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>142.8</td>\n",
       "      <td>151.6</td>\n",
       "      <td>167.2</td>\n",
       "      <td>175.6</td>\n",
       "      <td>168.0</td>\n",
       "      <td>170.8</td>\n",
       "      <td>164.0</td>\n",
       "      <td>188.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>142.0</td>\n",
       "      <td>151.2</td>\n",
       "      <td>166.8</td>\n",
       "      <td>175.2</td>\n",
       "      <td>167.6</td>\n",
       "      <td>170.4</td>\n",
       "      <td>164.0</td>\n",
       "      <td>188.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>187.2</td>\n",
       "      <td>200.4</td>\n",
       "      <td>218.0</td>\n",
       "      <td>230.8</td>\n",
       "      <td>221.2</td>\n",
       "      <td>224.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>247.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>187.6</td>\n",
       "      <td>200.4</td>\n",
       "      <td>218.0</td>\n",
       "      <td>231.2</td>\n",
       "      <td>221.2</td>\n",
       "      <td>224.0</td>\n",
       "      <td>214.4</td>\n",
       "      <td>247.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3      4      5      6      7\n",
       "0    184.0  196.0  217.2  227.6  217.2  224.8  215.2  246.8\n",
       "1    184.0  196.0  217.2  227.6  217.2  224.8  215.2  246.8\n",
       "2    184.8  198.0  216.4  228.0  218.0  222.0  214.4  244.4\n",
       "3    185.2  198.0  216.4  228.0  218.0  222.0  214.4  244.8\n",
       "4    184.8  198.0  216.4  228.0  218.0  222.0  214.4  244.4\n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...\n",
       "295  148.4  157.6  174.0  182.0  174.8  177.6  170.8  196.0\n",
       "296  142.8  151.6  167.2  175.6  168.0  170.8  164.0  188.4\n",
       "297  142.0  151.2  166.8  175.2  167.6  170.4  164.0  188.4\n",
       "298  187.2  200.4  218.0  230.8  221.2  224.0  214.0  247.6\n",
       "299  187.6  200.4  218.0  231.2  221.2  224.0  214.4  247.6\n",
       "\n",
       "[300 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train24_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.463858\n",
       "1    0.460422\n",
       "7    0.459063\n",
       "2    0.458386\n",
       "6    0.457046\n",
       "5    0.454014\n",
       "3    0.453864\n",
       "4    0.453436\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 24 Training - Create Dataframe objects and compute correlations\n",
    "train24_data_df = pd.DataFrame(train24_data)\n",
    "train24_label_s = pd.Series(train24_label)\n",
    "train24_data_df.corrwith(train24_label_s).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.340003\n",
       "7    0.336068\n",
       "0    0.334142\n",
       "3    0.328676\n",
       "4    0.326465\n",
       "2    0.322266\n",
       "5    0.321756\n",
       "6    0.316479\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12 Training - Create Dataframe objects and compute correlations\n",
    "train12_data_df = pd.DataFrame(train12_data)\n",
    "train12_label_s = pd.Series(train12_label)\n",
    "train12_data_df.corrwith(train12_label_s).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.557416\n",
       "7    0.556167\n",
       "3    0.543263\n",
       "5    0.541591\n",
       "0    0.538942\n",
       "6    0.536256\n",
       "1    0.533801\n",
       "2    0.533271\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6 Training - Create Dataframe objects and compute correlations\n",
    "train6_data_df = pd.DataFrame(train6_data)\n",
    "train6_label_s = pd.Series(train6_label)\n",
    "train6_data_df.corrwith(train6_label_s).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation between features seems to be about equal for predictions with training and test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training chips num:  [ 7 11  3 17 27  1  4  2  9  6 26 18 22 16 23 13 24 20 19 31 10 33 25 28]\n",
      "Type selection: ['TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TI', 'TF', 'TF', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [11 13 19 24 26 20 29 15  9 31 28  7]\n",
      "Type selection: ['TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF', 'TF', 'TI', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [30 31 25 18  2 27]\n",
      "Type selection: ['TF', 'TI', 'TF', 'TF', 'TI', 'TI']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 9}\n",
      "Best Accuracy:  0.96\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 4}\n",
      "Best Accuracy:  0.8933333333333333\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 5}\n",
      "Best Accuracy:  1.0\n",
      "Training chips num:  [30 26 23  4 14 13 10 22  7 28 11 16  8  2 31 17 27 12 18  5 25  3 15 33]\n",
      "Type selection: ['TF', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI', 'TF', 'TF', 'TF', 'TF', 'TI', 'TF', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI', 'TF']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [27 23 28  3 31 26  9 25 22 30 13 15]\n",
      "Type selection: ['TI', 'TI', 'TI', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [17  1 26 29 28 16]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TF', 'TF', 'TI']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 4}\n",
      "Best Accuracy:  0.9299999999999999\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 4}\n",
      "Best Accuracy:  0.9466666666666667\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 5}\n",
      "Best Accuracy:  0.8666666666666668\n",
      "Training chips num:  [12 27 29 32 10 28 22 14 23  1 21 13 16  4  9  6 25 19 24 31 26 30  2  7]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TI', 'TI', 'TI', 'TF', 'TI', 'TF', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [24  4 19 14  6  7  1 26 28 31 15 10]\n",
      "Type selection: ['TI', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [ 2 32 12  1 23 24]\n",
      "Type selection: ['TF', 'TF', 'TF', 'TI', 'TI', 'TI']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 5}\n",
      "Best Accuracy:  0.9266666666666667\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 6}\n",
      "Best Accuracy:  0.9333333333333333\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  1.0\n",
      "Training chips num:  [28 14 10 30  4 24  7 21 31 20 18  8  2 23  9 15  6 12 27 22 32  5 33 25]\n",
      "Type selection: ['TI', 'TF', 'TI', 'TI', 'TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TF', 'TF', 'TI', 'TF', 'TF', 'TI', 'TF']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [19 23 12 15 32 21  9 16 26 14  2 27]\n",
      "Type selection: ['TF', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [ 5 19 28 29 18  7]\n",
      "Type selection: ['TI', 'TI', 'TI', 'TF', 'TF', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  0.9066666666666666\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  0.9466666666666667\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 4}\n",
      "Best Accuracy:  0.9200000000000002\n",
      "Training chips num:  [12 21 23  4 10 13 19  1 22 14 24 26  7 18 17 27  8 28 20 15  9 25 33  2]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TF', 'TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [18 11 15 17 29 12  7 10  4 32 30  3]\n",
      "Type selection: ['TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TF', 'TF', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [22 33  5 28 32  8]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TI', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 4}\n",
      "Best Accuracy:  0.9666666666666666\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 8}\n",
      "Best Accuracy:  0.9200000000000002\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 5}\n",
      "Best Accuracy:  0.9333333333333333\n",
      "Training chips num:  [10 17  5 24 30 13 23 19 27 21 33 11 15 29 12  3 16 25  7 14 20 31 28  8]\n",
      "Type selection: ['TF', 'TF', 'TF', 'TF', 'TI', 'TF', 'TF', 'TF', 'TF', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TI', 'TI', 'TI', 'TI', 'TI', 'TI', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [ 3 28 31 24 17 14 15 32  7 27 33  6]\n",
      "Type selection: ['TF', 'TI', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [19 25  7  9 23 16]\n",
      "Type selection: ['TI', 'TI', 'TI', 'TF', 'TF', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 8}\n",
      "Best Accuracy:  0.93\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 4}\n",
      "Best Accuracy:  0.9800000000000001\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  1.0\n",
      "Training chips num:  [24 20 29  7  4 15  2  1 28 14  3 25 23  5  9 16 11 22 13 31 33 27 21  8]\n",
      "Type selection: ['TI', 'TI', 'TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TF', 'TF', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [ 4 10  8 14 28 16  5 18  7 21  2 20]\n",
      "Type selection: ['TF', 'TI', 'TI', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [32 27 11 16  2 12]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TI', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  0.9700000000000001\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  0.8933333333333335\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 9}\n",
      "Best Accuracy:  0.96\n",
      "Training chips num:  [24  8 10 11 13  2  7 25 16 21  9 23 20 12  4 32 30 22  6 18 33  1 15  3]\n",
      "Type selection: ['TF', 'TF', 'TF', 'TF', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TI', 'TI', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [ 3 23 11 27  7  5  8 26 14 13 32 29]\n",
      "Type selection: ['TI', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [15 33  7 21 31 27]\n",
      "Type selection: ['TF', 'TI', 'TI', 'TI', 'TF', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 8}\n",
      "Best Accuracy:  0.9533333333333334\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 5}\n",
      "Best Accuracy:  0.9733333333333334\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  0.96\n",
      "Training chips num:  [25 29 27  9 11  8 21 13  5 31  6 32  4 19 28 23 24 15 33  3 18 26  7 22]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [ 9  8  4 15 19 12 25  5 18 10 23 11]\n",
      "Type selection: ['TF', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TI', 'TF', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [22 12 28  4  6  3]\n",
      "Type selection: ['TF', 'TI', 'TI', 'TF', 'TF', 'TI']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 9}\n",
      "Best Accuracy:  0.9433333333333334\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  0.9400000000000001\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "Training chips num:  [25 24 21  2 19 17 28  3 10  9 13 27 29 33  4  6 12 32 18  1 23 14 22 20]\n",
      "Type selection: ['TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TF', 'TF', 'TI', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [30 25 12  6 19 10 31 17  4 11 18 33]\n",
      "Type selection: ['TI', 'TI', 'TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TF', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [26  8  2 13 11 10]\n",
      "Type selection: ['TI', 'TI', 'TI', 'TF', 'TF', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 5}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 9}\n",
      "Best Accuracy:  0.9133333333333333\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 4}\n",
      "Best Accuracy:  0.9466666666666667\n",
      "Training chips num:  [33 10 24 19 30  3 31  4 21  5 18  9 25 23 14 17 27  2 29  7 12 13 11 28]\n",
      "Type selection: ['TF', 'TF', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TF', 'TF', 'TI', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [ 6 30 18 16 14 29  7 25 10  8  9  4]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [21 19 23 15 29 12]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TI', 'TF', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 8}\n",
      "Best Accuracy:  0.9433333333333331\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 9}\n",
      "Best Accuracy:  0.9466666666666667\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  0.9066666666666668\n",
      "Training chips num:  [ 1 30  9 19 17  3 28 15  8 14  2 20 18 21 32 16 23 31 12 29 22 33  4 25]\n",
      "Type selection: ['TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TF', 'TF', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [33 24  7 29  2 17 12 21 26 22 27  9]\n",
      "Type selection: ['TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [ 5 17 26 14 21 29]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TF', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 3}\n",
      "Best Accuracy:  0.97\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  0.9400000000000001\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 4}\n",
      "Best Accuracy:  0.8666666666666668\n",
      "Training chips num:  [13  1 28 26  9  6 10 30  5 23 25 16 32 18 15 17 21 27 14  7  4 29 24  2]\n",
      "Type selection: ['TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF', 'TF', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [22 11 25  9 30 10  7 31 14 20 15 12]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TI', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [18 33  1 19 12  7]\n",
      "Type selection: ['TF', 'TI', 'TI', 'TF', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 8}\n",
      "Best Accuracy:  0.9566666666666667\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 3}\n",
      "Best Accuracy:  0.9933333333333334\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  1.0\n",
      "Training chips num:  [ 2 15 30  4  6 25 12 29 16 19 33 23 21 32 24 28 22  3 10 31 17 11  7 26]\n",
      "Type selection: ['TF', 'TF', 'TI', 'TI', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TI', 'TI', 'TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TF', 'TF', 'TF']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [ 4 14  8 32 10 24  3 23  7 29 20 28]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [ 1 20 29 18 16  7]\n",
      "Type selection: ['TF', 'TF', 'TF', 'TI', 'TI', 'TI']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  0.9466666666666667\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  0.9400000000000001\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 9}\n",
      "Best Accuracy:  0.9600000000000002\n",
      "Training chips num:  [ 5 18 27 10 30  2  3  1 20 21 15  6 28 16 22 13  9  8 17 33 26 24 32 12]\n",
      "Type selection: ['TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TF', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [ 1 19 30 24  4 14 28  5  8 10  6 32]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [31 23 30 15 21 13]\n",
      "Type selection: ['TF', 'TI', 'TI', 'TF', 'TF', 'TI']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  0.9366666666666668\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  0.9066666666666666\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 6}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "Training chips num:  [33 31 32 16 30  2 25 12  6  8 27 13 19 24 20  5  3 22  1  4 17 15 18 29]\n",
      "Type selection: ['TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TI', 'TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF', 'TF']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [10 29  8 31 33 28 13  9 32 17 12  5]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [ 2 20 26  9  4 33]\n",
      "Type selection: ['TI', 'TF', 'TI', 'TF', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 8}\n",
      "Best Accuracy:  0.89\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 4}\n",
      "Best Accuracy:  0.9200000000000002\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  1.0\n",
      "Training chips num:  [ 7  1 32 12  2 28 24 11 21 26 19 33  9 15  8 14 16 25 23 31  5 13 20 17]\n",
      "Type selection: ['TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TF']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [12 26 29 28  7 15 20  6 27 19 25 33]\n",
      "Type selection: ['TI', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [ 4 22 18 32  7  5]\n",
      "Type selection: ['TI', 'TF', 'TI', 'TF', 'TF', 'TI']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 4}\n",
      "Best Accuracy:  0.9566666666666667\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  0.9333333333333333\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  1.0\n",
      "Training chips num:  [19  3 17 30 18 13 25 20 26 11  1 10 16 27  4 23  9  5 24 31 21 33 28  2]\n",
      "Type selection: ['TI', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TF', 'TI', 'TF']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [21 33 29 11 27 16  4 15 14 12 22 17]\n",
      "Type selection: ['TF', 'TI', 'TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [23 10 31 28 17 14]\n",
      "Type selection: ['TF', 'TI', 'TF', 'TI', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 3}\n",
      "Best Accuracy:  0.9533333333333334\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  0.9866666666666667\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  0.9733333333333334\n",
      "Training chips num:  [29 25 10  8  7 21 18 24 11  9 19 32 22  2 17 33 16 12 31  4 28 15 23  1]\n",
      "Type selection: ['TF', 'TF', 'TI', 'TI', 'TI', 'TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TF', 'TI', 'TF', 'TI', 'TF', 'TF', 'TF', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [ 2 23 13 18  6 10 22 28 12 15 19  5]\n",
      "Type selection: ['TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TI', 'TF', 'TI', 'TF', 'TF', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [ 1 29 28 33  3 32]\n",
      "Type selection: ['TF', 'TI', 'TI', 'TF', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 4}\n",
      "Best Accuracy:  0.9266666666666667\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 3}\n",
      "Best Accuracy:  0.9400000000000001\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 8}\n",
      "Best Accuracy:  0.9466666666666669\n",
      "Training chips num:  [12 16 33  6 15 20 11 30 18 13 17 14  8 27 23 28  1  5 21 25  9 24 19 26]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TF']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [19 27  1 23 13 30  3 26 10 24  4 14]\n",
      "Type selection: ['TI', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TF', 'TF', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [31 26 10 29 30 21]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TI', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  1.0\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 9}\n",
      "Best Accuracy:  0.9333333333333333\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      " {'knc__leaf_size': 2, 'knc__n_neighbors': 2}\n",
      "Best Accuracy:  0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "# Creating KNeighborsClassifier Pipeline\n",
    "KneighC = Pipeline([('scaler',StandardScaler()),('knc', KNeighborsClassifier())])\n",
    "\n",
    "# Finding the best parameters for KNeighborsClassifier\n",
    "\n",
    "## Create parameter grid for gridsearch algorithm\n",
    "knc_param_Grid=  { 'knc__n_neighbors': np.arange(2,10,1),\n",
    "                  'knc__leaf_size': np.arange(2,30,2),\n",
    "                 }\n",
    "\n",
    "## Create Grid search\n",
    "knc_grid_search = GridSearchCV(KneighC,\n",
    "                               param_grid=knc_param_Grid,\n",
    "                               scoring='accuracy',\n",
    "                               refit=True,\n",
    "                               cv=5,\n",
    "                               verbose=1)\n",
    "\n",
    "ii=0\n",
    "### Fit to training data\n",
    "KNC_trainscores=[]\n",
    "KNC_testscores=[]\n",
    "while ii < 20:\n",
    "\n",
    "    # Splits for each dataset\n",
    "    train24_data, train24_label, test24_data, test24_label = train_test_split(24,1,csv_path)\n",
    "    train12_data, train12_label, test12_data, test12_label = train_test_split(12,1,csv_path)\n",
    "    train6_data, train6_label, test6_data, test6_label = train_test_split(6,1,csv_path)\n",
    "    \n",
    "    train24_data = pd.DataFrame(train24_data)\n",
    "    test24_data = pd.DataFrame(test24_data)\n",
    "    \n",
    "    train12_data = pd.DataFrame(train12_data)\n",
    "    test12_data = pd.DataFrame(test12_data)\n",
    "    \n",
    "    train6_data = pd.DataFrame(train6_data)\n",
    "    test6_data = pd.DataFrame(test6_data)\n",
    "    \n",
    "\n",
    "    # Create lists of training sets to parse\n",
    "    training_sets = [train24_data, train12_data, train6_data]\n",
    "    training_labels = [train24_label, train12_label, train6_label]\n",
    "    \n",
    "    # Create lists of test sets to parse\n",
    "    test_sets = [test24_data, test12_data, test6_data]\n",
    "    test_labels =[test24_label, test12_label, test6_label]\n",
    "    \n",
    "    Sets = [\"-----24 Sample Training Set-----\",\"-----12 Sample Training Set-----\", \"-----6 Sample Training Set-----\"]\n",
    "    t_sets = [\"-----24 Sample Test Set-----\",\"-----12 Sample Test Set-----\", \"-----6 Sample Test Set-----\"]\n",
    "    \n",
    "    #Iterater\n",
    "    ii = ii + 1\n",
    "    \n",
    "    # Loop responsible for parsing training sets and training labels\n",
    "    for (a,i,j,m,n) in zip(Sets, training_sets,training_labels, test_sets, test_labels):\n",
    "        print(\"\\n\",a,\"\\n\")\n",
    "        knc_grid_search.fit(i,j)\n",
    "        ### Print Best parameters\n",
    "        print(\"\\n\",knc_grid_search.best_params_)\n",
    "        ## Saving the tuned model\n",
    "        model = knc_grid_search.best_estimator_\n",
    "        print(\"Best Accuracy: \",knc_grid_search.best_score_)\n",
    "        KNC_trainscores+= [knc_grid_search.best_score_]\n",
    "        y_pred = model.predict(m)\n",
    "        KNC_testscores += [accuracy_score(n,y_pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for KneighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Kneighbors Accuracy Scores----------\n",
      "TRAIN24 Average Accuracy:  0.9443333333333334\n",
      "Test24 Average Accruacy:  0.9213333333333333\n",
      "Train12 Average Accuracy:  0.9390000000000001\n",
      "Test12 Average Accruacy:  0.9253333333333333\n",
      "TRAIN6 Average Accuracy:  0.9533333333333334\n",
      "Test6 Average Accruacy:  0.9101481481481482\n"
     ]
    }
   ],
   "source": [
    "# Slicing training scores into individual lists\n",
    "KNC_24_train_scores = KNC_trainscores[0::3]\n",
    "KNC_12_train_scores= KNC_trainscores[1::3]\n",
    "KNC_6_train_scores = KNC_trainscores[2::3]\n",
    "\n",
    "# Slicing test scores into individual lists\n",
    "KNC_24_test_scores = KNC_testscores[0::3]\n",
    "KNC_12_test_scores = KNC_testscores[1::3]\n",
    "KNC_6_test_scores = KNC_testscores[2::3]\n",
    "\n",
    "print(\"---------- Kneighbors Accuracy Scores----------\")\n",
    "\n",
    "# Accuracy scores for test and training sets\n",
    "train24_avg = mean(KNC_24_train_scores)\n",
    "test24_avg = mean(KNC_24_test_scores)\n",
    "print(\"TRAIN24 Average Accuracy: \", train24_avg)\n",
    "print(\"Test24 Average Accruacy: \" , test24_avg)\n",
    "\n",
    "# Accuracy scores for test and training sets\n",
    "train12_avg = mean(KNC_12_train_scores)\n",
    "test12_avg = mean(KNC_12_test_scores)\n",
    "print(\"Train12 Average Accuracy: \", train12_avg)\n",
    "print(\"Test12 Average Accruacy: \" , test12_avg)\n",
    "\n",
    "# Accuracy Scores for test and training sets\n",
    "train6_avg = mean(KNC_6_train_scores)\n",
    "test6_avg = mean(KNC_6_test_scores)\n",
    "print(\"TRAIN6 Average Accuracy: \", train6_avg)\n",
    "print(\"Test6 Average Accruacy: \" , test6_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training chips num:  [28 32  9 22 10 33 23 19  3 20  1 15 29 30 16 21 25 26 11  4 27 31 12 14]\n",
      "Type selection: ['TF', 'TF', 'TF', 'TF', 'TI', 'TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TI', 'TF', 'TF', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [13 28 23 27  9  7 26 12 31  3 29 25]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TF', 'TF', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [14  1 16 32 20 31]\n",
      "Type selection: ['TF', 'TI', 'TI', 'TF', 'TF', 'TI']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.3, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9966666666666667\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9200000000000002\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.1, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9733333333333334\n",
      "Training chips num:  [ 1 16 25 19 20 10 33 29 32 14  9 31  3 22 27 17  6  4  5 12 28 18 30 15]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TF', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [18 22 24 21 30 27 14  7  2 15 10 28]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [ 5 26  8 17 23 30]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TI', 'TF', 'TI']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.3, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9266666666666665\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9200000000000002\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9200000000000002\n",
      "Training chips num:  [13 27 10 29 14 32  5 24 20 26 12 33 18 11 17  3 19 30  6 21 28  8 15  4]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [17 27  2 30 19 11 14  5 12  7  6 25]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [17  9 27 12 20 21]\n",
      "Type selection: ['TI', 'TI', 'TI', 'TF', 'TF', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.01, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9266666666666665\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9200000000000002\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.5, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  1.0\n",
      "Training chips num:  [ 1 15 17  8  5 22 27 32 30 21 33 23 25 24 14 10 29 16 11 12 13  3 19  7]\n",
      "Type selection: ['TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TI', 'TF', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [29  3 15  5  9  4 23 28 33 20 18 32]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [26 16 14  7  9  6]\n",
      "Type selection: ['TF', 'TI', 'TI', 'TF', 'TF', 'TI']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9200000000000002\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.4, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  1.0\n",
      "Training chips num:  [24 12 15 18 23 33 32  5 10 11  8 27 21 20  2 30 17 28 31 25  1 16 14 29]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TF', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI', 'TF']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [ 5 29 27 14 20 21 16 28 22  3 25 23]\n",
      "Type selection: ['TF', 'TI', 'TF', 'TF', 'TI', 'TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [16 14 22 25  6 24]\n",
      "Type selection: ['TI', 'TF', 'TI', 'TF', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.2, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9733333333333334\n",
      "Training chips num:  [13  6 21 15 17 27 25 10 16 18 19 11 22  9 32 28 33 26 30 24 12  2 23  1]\n",
      "Type selection: ['TF', 'TF', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TI', 'TF', 'TF', 'TF', 'TF', 'TI', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [14  3  9  5 33 16 27  1  6 31  4 28]\n",
      "Type selection: ['TF', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [30 33  7 22  4  6]\n",
      "Type selection: ['TI', 'TI', 'TI', 'TF', 'TF', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9200000000000002\n",
      "Training chips num:  [ 8  1  5 17 27 15 23 33 24 26 21 10 20 12 28  2 16 13 11  9  3  6 18 19]\n",
      "Type selection: ['TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [32 26 11  5 23 31 13 10 29 27 12 19]\n",
      "Type selection: ['TF', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TI', 'TF', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [15 22 24 17 31 13]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TI', 'TF', 'TI']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.2, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9666666666666666\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.2, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  1.0\n",
      "Training chips num:  [20 21 11 33 30  3  4 12 14  2 19 26 24 23  5 22 27 29  6 32 13 18  7 31]\n",
      "Type selection: ['TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TF', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TI', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [27  1  9 11  3 12 13 29 28 22  2 14]\n",
      "Type selection: ['TF', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [ 8 26 14 21 13  2]\n",
      "Type selection: ['TF', 'TI', 'TF', 'TI', 'TF', 'TI']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.01, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9266666666666667\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.1, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9400000000000001\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "Training chips num:  [26 21  4  5 11 14 18 22  1 15 12 19  9 20 10 27 17  2 25  8 32 29 16  7]\n",
      "Type selection: ['TF', 'TF', 'TI', 'TF', 'TF', 'TI', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [31 27 12 13  7 18 14 20 26  6 32  3]\n",
      "Type selection: ['TF', 'TI', 'TI', 'TF', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [29 27 21 20 17 10]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TI', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.1, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9266666666666665\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.3, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.96\n",
      "Training chips num:  [ 4 11  2 29 20 13 22  3 32  8 15  5 16 14 19 10 17 12 27 24  7 25 23  9]\n",
      "Type selection: ['TF', 'TI', 'TI', 'TF', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TF']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [27 17 19 28  3  9 31  1  8  4 13 30]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF', 'TF', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [12 23 32  9 28  5]\n",
      "Type selection: ['TF', 'TF', 'TI', 'TI', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9200000000000002\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.3, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9333333333333332\n",
      "Training chips num:  [11  3 21 25 19  1 32 27 24  9 23 10 18  6 14 28 16 13 26 17  7 30  4  5]\n",
      "Type selection: ['TF', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [12 28  9 15  2  1  3 33 30  5  7 31]\n",
      "Type selection: ['TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [20 29  2  4 13 30]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TF', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.2, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.93\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.1, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9733333333333334\n",
      "Training chips num:  [21 27 16  5 25 29  7 13 15 14 22  8 26 23  6 10 30  2 18  1 12 11 20 19]\n",
      "Type selection: ['TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TF', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [28  2  4  7  8 14 24 29 12 21  3 23]\n",
      "Type selection: ['TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TI', 'TF', 'TF', 'TI', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [ 3 31  6 28 20  8]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TF', 'TF', 'TI']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.6, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  1.0\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.5, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9733333333333334\n",
      "Training chips num:  [ 7 13 15 19 33 11 12 23 31 17  9 30  4 25 22 21 28 18 14 20 24 32 29 10]\n",
      "Type selection: ['TF', 'TF', 'TI', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TI', 'TF', 'TF', 'TI', 'TF', 'TF', 'TI', 'TI', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [ 2 13 16 23  9 12 32 33  3 15 19  6]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [ 6 31 26 29 14 28]\n",
      "Type selection: ['TI', 'TF', 'TI', 'TF', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.7, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  1.0\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9200000000000002\n",
      "Training chips num:  [12  5 13  3 17 24 14  9 21  7 10 22 27 20 11 26 18  6 28 33 30  4 32  8]\n",
      "Type selection: ['TI', 'TI', 'TI', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TF', 'TF', 'TI', 'TF', 'TI', 'TF', 'TF', 'TF', 'TF', 'TF', 'TI', 'TI', 'TF', 'TI', 'TF']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [31 18 14  6 26  9 11 23 10  2 29 13]\n",
      "Type selection: ['TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TI', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [ 8 29 15 21  6  4]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TF', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.01, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9266666666666665\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.2, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9733333333333334\n",
      "Training chips num:  [11  4 24  6  3 32 12 19 23 26  8 14 25 33  9 17 28  1 22 20  2 16 30 13]\n",
      "Type selection: ['TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [32 13 22 19 21 12 10 29 18 17 27  9]\n",
      "Type selection: ['TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TI', 'TF', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [29 14 20 18 33  8]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TI', 'TF', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.01, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9266666666666665\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9200000000000002\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.2, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9466666666666667\n",
      "Training chips num:  [17  8 23 11  5 19  6 21  3 27 10 32  9 30 12 31 22 16 26 24  4 25 14 33]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TF', 'TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF', 'TF', 'TI', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [ 8  5 33 13  7 26 21 28 19 31 10 27]\n",
      "Type selection: ['TI', 'TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [ 3 21 18 17 31 27]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TI', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.2, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9333333333333333\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9200000000000002\n",
      "Training chips num:  [31 29 26 33 17 28 10  6 15 13  3  2 18 27  9  1  7 24  4 12  8 23  5 11]\n",
      "Type selection: ['TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TI', 'TI', 'TI', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [18 32 17  8 14 28  7 16 13 31  2 20]\n",
      "Type selection: ['TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TF']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [17 24  6 27 18 12]\n",
      "Type selection: ['TF', 'TI', 'TI', 'TI', 'TF', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.1, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9266666666666667\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9200000000000002\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.1, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9466666666666667\n",
      "Training chips num:  [ 8 26 33 30 22  4 24 12  5 23 29 32 31  6 19 25 11  2 15 20 16  3 21 10]\n",
      "Type selection: ['TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TF', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TI', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [13 10  1  7 31  8 22 17  9 28 23 18]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TF', 'TF', 'TF', 'TI', 'TI', 'TF', 'TI', 'TI', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [13  2  8 28 18  5]\n",
      "Type selection: ['TF', 'TI', 'TI', 'TF', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9200000000000002\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "Training chips num:  [22  4 27 29 19 16 25 14 32 31  1 18  7 24 10 28  2 26  3 15 20 33 11 13]\n",
      "Type selection: ['TI', 'TF', 'TF', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TI', 'TF', 'TI', 'TF', 'TI', 'TF', 'TI', 'TI']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [17  8  3 19 10 27 33  2 24 11 15 16]\n",
      "Type selection: ['TI', 'TF', 'TI', 'TF', 'TF', 'TF', 'TF', 'TI', 'TI', 'TF', 'TI', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [26 33 23 24 29 22]\n",
      "Type selection: ['TF', 'TF', 'TI', 'TI', 'TI', 'TF']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.01, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9333333333333332\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.1, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9400000000000001\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.4, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  1.0\n",
      "Training chips num:  [ 3 13 16  8 31 29 14 18 23  9 10 17 12  1 22  6 28 11  2 15 24 26 27  4]\n",
      "Type selection: ['TI', 'TF', 'TI', 'TI', 'TI', 'TI', 'TF', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TF', 'TF', 'TF']\n",
      "TI: 12\n",
      "TF: 12\n",
      "Training chips num:  [14 18 17 27 26 32  6 21  4 10  9  3]\n",
      "Type selection: ['TF', 'TI', 'TI', 'TF', 'TF', 'TF', 'TF', 'TI', 'TF', 'TI', 'TI', 'TI']\n",
      "TI: 6\n",
      "TF: 6\n",
      "Training chips num:  [22 10 27 15 26  1]\n",
      "Type selection: ['TF', 'TF', 'TF', 'TI', 'TI', 'TI']\n",
      "TI: 3\n",
      "TF: 3\n",
      "\n",
      " -----24 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "\n",
      " -----12 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.001, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9199999999999999\n",
      "\n",
      " -----6 Sample Training Set----- \n",
      "\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "\n",
      " {'logreg__C': 0.1, 'logreg__tol': 0.0001}\n",
      "Best Accuracy:  0.9466666666666669\n"
     ]
    }
   ],
   "source": [
    "# Create Logisitic Regression Model\n",
    "Logreg = Pipeline([('scaler',StandardScaler()),('logreg',LogisticRegression(random_state=42))])\n",
    "Logreg\n",
    "\n",
    "# Finding the best parameters for Logistic Regression\n",
    "\n",
    "## Create Parameter Grid\n",
    "logreg_param_grid = {'logreg__C': [0.001,0.01,0.1,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n",
    "                     'logreg__tol': [0.0001, 0.001, 0.01]\n",
    "                    }\n",
    "\n",
    "## Create Log Reg Gridsearch\n",
    "logreg_gridsearch = GridSearchCV(Logreg,\n",
    "                                 param_grid=logreg_param_grid,\n",
    "                                 scoring='accuracy',\n",
    "                                 refit=True,\n",
    "                                 cv=5,\n",
    "                                 verbose=1)\n",
    "\n",
    "\n",
    "ii=0\n",
    "### Fit to training data\n",
    "logreg_trainscores=[]\n",
    "logreg_testscores=[]\n",
    "while ii < 20:\n",
    "\n",
    "    # Splits for each dataset\n",
    "    train24_data, train24_label, test24_data, test24_label = train_test_split(24,1,csv_path)\n",
    "    train12_data, train12_label, test12_data, test12_label = train_test_split(12,1,csv_path)\n",
    "    train6_data, train6_label, test6_data, test6_label = train_test_split(6,1,csv_path)\n",
    "    \n",
    "    # Create pandas dataframes and series\n",
    "    train24_data = pd.DataFrame(train24_data)\n",
    "    test24_data = pd.DataFrame(test24_data)\n",
    "    \n",
    "    train12_data = pd.DataFrame(train12_data)\n",
    "    test12_data = pd.DataFrame(test12_data)\n",
    "    \n",
    "    train6_data = pd.DataFrame(train6_data)\n",
    "    test6_data = pd.DataFrame(test6_data)\n",
    "    \n",
    "    # Create lists of training sets to parse\n",
    "    training_sets = [train24_data, train12_data, train6_data]\n",
    "    training_labels = [train24_label, train12_label, train6_label]\n",
    "    \n",
    "    # Create lists of test sets to parse\n",
    "    test_sets = [test24_data, test12_data, test6_data]\n",
    "    test_labels =[test24_label, test12_label, test6_label]\n",
    "    \n",
    "    Sets = [\"-----24 Sample Training Set-----\",\"-----12 Sample Training Set-----\", \"-----6 Sample Training Set-----\"]\n",
    "    t_sets = [\"-----24 Sample Test Set-----\",\"-----12 Sample Test Set-----\", \"-----6 Sample Test Set-----\"]\n",
    "    \n",
    "    #Iterater\n",
    "    ii = ii + 1\n",
    "    \n",
    "    # Loop responsible for parsing training sets and training labels\n",
    "    for (a,i,j,m,n) in zip(Sets, training_sets,training_labels, test_sets, test_labels):\n",
    "        print(\"\\n\",a,\"\\n\")\n",
    "        logreg_gridsearch.fit(i,j)\n",
    "        ### Print Best parameters\n",
    "        print(\"\\n\",logreg_gridsearch.best_params_)\n",
    "        ## Saving the tuned model\n",
    "        model = logreg_gridsearch.best_estimator_\n",
    "        print(\"Best Accuracy: \",logreg_gridsearch.best_score_)\n",
    "        logreg_trainscores+= [logreg_gridsearch.best_score_]\n",
    "        y_pred = model.predict(m)\n",
    "        logreg_testscores += [accuracy_score(n,y_pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Reg Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Logistic Regression Accuracy Scores----------\n",
      "TRAIN24 Average Accuracy:  0.9273333333333332\n",
      "Test24 Average Accruacy:  0.91\n",
      "Train12 Average Accuracy:  0.933\n",
      "Test12 Average Accruacy:  0.92\n",
      "TRAIN6 Average Accuracy:  0.9560000000000001\n",
      "Test6 Average Accruacy:  0.9130370370370371\n"
     ]
    }
   ],
   "source": [
    "# Slicing training scores into individual lists\n",
    "logreg_24_train_scores = logreg_trainscores[0::3]\n",
    "logreg_12_train_scores= logreg_trainscores[1::3]\n",
    "logreg_6_train_scores = logreg_trainscores[2::3]\n",
    "\n",
    "# Slicing test scores into individual lists\n",
    "logreg_24_test_scores = logreg_testscores[0::3]\n",
    "logreg_12_test_scores = logreg_testscores[1::3]\n",
    "logreg_6_test_scores = logreg_testscores[2::3]\n",
    "\n",
    "print(\"---------- Logistic Regression Accuracy Scores----------\")\n",
    "\n",
    "# Accuracy scores for test and training sets\n",
    "train24_avg = mean(logreg_24_train_scores)\n",
    "test24_avg = mean(logreg_24_test_scores)\n",
    "print(\"TRAIN24 Average Accuracy: \", train24_avg)\n",
    "print(\"Test24 Average Accruacy: \" , test24_avg)\n",
    "\n",
    "# Accuracy scores for test and training sets\n",
    "train12_avg = mean(logreg_12_train_scores)\n",
    "test12_avg = mean(logreg_12_test_scores)\n",
    "print(\"Train12 Average Accuracy: \", train12_avg)\n",
    "print(\"Test12 Average Accruacy: \" , test12_avg)\n",
    "\n",
    "# Accuracy Scores for test and training sets\n",
    "train6_avg = mean(logreg_6_train_scores)\n",
    "test6_avg = mean(logreg_6_test_scores)\n",
    "print(\"TRAIN6 Average Accuracy: \", train6_avg)\n",
    "print(\"Test6 Average Accruacy: \" , test6_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train24_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(\u001b[43mtrain24_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m,train24_data[:,\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eel4930\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eel4930\\lib\\site-packages\\pandas\\core\\indexes\\range.py:388\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mget_loc(key, method\u001b[38;5;241m=\u001b[39mmethod, tolerance\u001b[38;5;241m=\u001b[39mtolerance)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eel4930\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5637\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   5634\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5635\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5636\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5637\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0)"
     ]
    }
   ],
   "source": [
    "plt.scatter(train24_data[:,0],train24_data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Kmeans Model\n",
    "Kmeans = Pipeline([('scaler', StandardScaler()),('kmeans',KMeans())])\n",
    "Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DBSCAN Model\n",
    "dbscan = Pipeline([('scaler',StandardScaler()),('dbscan', DBSCAN())])\n",
    "dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "29072eab1d961a779b4af8c415f001d7e62f2cfb4f62e34692f6d23b566fb2eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
